{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN/F7MgXu+8hVkH6DQkksKh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fmeRAWGJ0aq2"},"outputs":[],"source":["'''\n","\n","References and Credits:\n","Reading:\n","https://medium.com/data-science-in-your-pocket/lora-for-fine-tuning-llms-explained-with-codes-and-example-62a7ac5a3578\n","https://medium.com/@hayagriva99999/lora-and-qlora-an-efficient-approach-to-fine-tuning-large-models-under-the-hood-948468424cd6\n","https://lightning.ai/pages/community/lora-insights/\n","https://medium.com/@sujathamudadla1213/difference-between-qlora-and-lora-for-fine-tuning-llms-0ea35a195535\n","\n","Examples:\n","https://medium.com/@ichigo.v.gen12/understanding-lora-with-python-implementation-31375d2d1c10\n","Existing code:\n","https://colab.research.google.com/github/brevdev/notebooks/blob/main/mistral-finetune.ipynb#scrollTo=VCJnpZoayRgq\n","https://github.com/samlhuillier/viggo-finetune/blob/main/llama/fine-tune-code-llama.ipynb\n","\n","'''"]}]}